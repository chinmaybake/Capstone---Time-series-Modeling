{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHINMAY BAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REQUIRED PYTHON MODULES \n",
    "\n",
    "import pyodbc\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.ar_model import AR\n",
    "from statsmodels.tsa.ar_model import AutoReg,ar_select_order\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from statsmodels.tsa.stattools import pacf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OVERVIEW OF THE FORECASTING AUTOMATION FUNCTION\n",
    "\n",
    "**REQUIREMENTS -**\n",
    "\n",
    "1) Required Python Modules - Listed in line of the Notebook\n",
    "\n",
    "\n",
    "**INTRODUCTION -**\n",
    "\n",
    "1) The function - **forecast_func** performs an AutoRegression based on **statsmodels API's AutoReg** function \n",
    "\n",
    "2) It has four main functions -\n",
    "\n",
    "*  Plucking the right dataframe and from the dataset and performing required **preprocessing** operations on it \n",
    "* Identifying the correct **decomposition methodology** based on analysing residuals of each decomposition method\n",
    "* Enumerating or listing the **lags** observed in the data \n",
    "* And finally, modeling the data with **Autoregressions**\n",
    "\n",
    "3) The inputs to the function are - \n",
    "\n",
    "* **Product ID** - Any valid product ID across the store ranges (Integer,Float)\n",
    "* **Store ID** - Any valid store ID for stores 1 to 15 only (Integer)\n",
    "* **Seasonality** - Either True or False - based on the seasonal characterstics of the entered product (Boolean)\n",
    "* **Seasonal Periodicity** - Frequency of seasonal occurences in the given product on a yearly scale (Integer)\n",
    "* NOTE: The inputs should be enetered in the above sequence while invoking the function. \n",
    "\n",
    "4) Outputs - Returns below objects in following sequence \n",
    "\n",
    "* **Forecasted values** over the period of the test data (Pandas Data Series)\n",
    "* **Plot** showing the goodness of fit (Matplotlib object)\n",
    "* **Root Mean Squared Error** (float)\n",
    "* **Mean Absolutely Scaled Error** (float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_func(PrdId,StrId,Seasonal_Periodicity:bool,Periodicity): # main function input\n",
    "    \n",
    "    # invoke the error block to check the authencticity of the input\n",
    "    check_error=error_block(PrdId,StrId) \n",
    "    \n",
    "    if type(check_error)==str:\n",
    "           # return error for incorrect inputs\n",
    "        return check_error              \n",
    "    else:\n",
    "        # data transformation function invoked\n",
    "        transform=data_transform(check_error)  \n",
    "        if Seasonal_Periodicity==True:\n",
    "            #Autoregression with seasonal parameters\n",
    "            AR=func_AR(transform,Seasonal_Periodicity,Periodicity,transform[3])  \n",
    "        else: \n",
    "            #Autoregression without seasonal parameters\n",
    "            AR=func_AR(transform,Seasonal_Periodicity,0,transform[3])  \n",
    "     \n",
    "    # Return a plot of forecasts\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(transform[2].iloc[int(len(transform[2]) * 0.8):], label='Observed')\n",
    "    plt.plot(AR[0], color='red', label='Predicted')\n",
    "    plt.xlabel(\"DATE\")\n",
    "    plt.ylabel(\"SALES\")\n",
    "    plt.legend()\n",
    "    plt.show()                      \n",
    "    # Return forecasts and error\n",
    "    print(AR)                       \n",
    "    \n",
    "def error_block(product,store):               \n",
    "    \n",
    "    if store>15 or store<1: \n",
    "        return \"Incorrect StoreID. Please try again.\"  # Store Id check\n",
    "    \n",
    "    cursor = cnxn.cursor()\n",
    "    \n",
    "    \n",
    "    if store in range(1,6,1):                       \n",
    "        sales_1_5_df = pd.read_sql_query('',cnxn)\n",
    "        sales_df_15=sales_1_5_df[''] == store\n",
    "        sales_df_15=sales_1_5_df[sales_df_15]\n",
    "    if store in range(6,11,1):\n",
    "        sales_6_10_df = pd.read_sql_query('',cnxn)\n",
    "        sales_df_15=sales_6_10_df[''] == store\n",
    "        sales_df_15=sales_6_10_df[sales_df_15]\n",
    "    if store in range(11,16,1): \n",
    "        sales_11_15_df = pd.read_sql_query('',cnxn)\n",
    "        sales_df_15 =sales_11_15_df[''] == store\n",
    "        sales_df_15=sales_11_15_df[sales_df_15]\n",
    "        \n",
    "    sales_15_test=sales_df_15.loc[:, ['']]\n",
    "    \n",
    "    # Product ID selection\n",
    "    x1=sales_15_test[sales_15_test['']==product]  \n",
    "    x1=x1.reset_index(drop=True)\n",
    "    x1=x1[['','']]\n",
    "    x1=x1.set_index('')\n",
    "    # Exclusion of negative values from the data \n",
    "    x1=x1.where(x1 > 0,0)                               \n",
    "    \n",
    "    if len(x1)==0: \n",
    "        # product ID check\n",
    "        return \"Incorrect ProductID. Please try again.\"\n",
    "    else: \n",
    "        # return product time series\n",
    "        return x1\n",
    "\n",
    "def data_transform(dataframe):\n",
    "    \n",
    "    # Daily resampling of given time series to fix any date index inconsistencies\n",
    "    x2=dataframe[''].resample('D').mean()    \n",
    "    \n",
    "    # Analysis of residuals for the selection of best decomposition methods\n",
    "    def acf1(x):\n",
    "        #sum of squares of autocorrelations\n",
    "        return np.square(sum(acf(x)))\n",
    "    \n",
    "    def ssacf(add,mult):\n",
    "        return np.where(acf1(add)<acf1(mult),\"additive\",\"multiplicative\")\n",
    "    #Multiplicative decomposition \n",
    "    mul = seasonal_decompose(x2 + 0.1,model='multiplicative',extrapolate_trend='freq')\n",
    "    #Additive decomposition\n",
    "    add = seasonal_decompose(x2,model='additive',extrapolate_trend='freq')\n",
    "    model_type = ssacf(add.resid,mul.resid)\n",
    "    \n",
    "    if model_type=='multiplicative':\n",
    "        #decomposition after selection of the appropriate decomposition method \n",
    "        model = seasonal_decompose(x2+0.1,model=str(model_type),extrapolate_trend='freq')\n",
    "    else: \n",
    "        model = seasonal_decompose(x2,model=str(model_type),extrapolate_trend='freq')\n",
    "        \n",
    "    #Lag order selection using statsmodels' ar_select_order\n",
    "    lags=ar_select_order(x2,30)\n",
    "    laglist=list(lags.ar_lags)\n",
    "    \n",
    "    #alternative method of enumerating lags based\n",
    "    ''''ar,ci =pacf(x2,alpha=0.05)\n",
    "    laglist=list()\n",
    "    for i in range(0,len(ar),1):\n",
    "        if ar[i]<(-0.1) or ar[i]>(0.1):\n",
    "            laglist.append(i)'''\n",
    "    \n",
    "    # removal of zeros from the lag list\n",
    "    for i in laglist: \n",
    "        if i==0: \n",
    "            laglist.remove(i)\n",
    "            \n",
    "    # handling a null laglist and setting default lag at 1 \n",
    "    if len(laglist)<1: \n",
    "        laglist=[1]\n",
    "            \n",
    "    return (model,laglist,x2,model_type)\n",
    "\n",
    "def func_AR(data,seasonal_period,duration,decomp): # Autoregression\n",
    "    \n",
    "    # Function to calculate mean absolutely scaled error \n",
    "    def MASE(training_series, testing_series, prediction_series):\n",
    "        n = training_series.shape[0]\n",
    "        d = np.abs(  np.diff( training_series) ).sum()/(n-1)\n",
    "        errors = np.abs(testing_series - prediction_series )\n",
    "        return errors.mean()/d\n",
    "    \n",
    "    # extraction of each decomposed component\n",
    "    component_dict = {'seasonal': data[0].seasonal, 'trend': data[0].trend, 'residual': data[0].resid}\n",
    "    prediction_results = []\n",
    "    \n",
    "    # 80:20 split\n",
    "    for component in ['seasonal', 'trend', 'residual']:\n",
    "        historic = component_dict[component].iloc[:int(len(data[2]) * 0.8)].to_list()\n",
    "        test = component_dict[component].iloc[int(len(data[2]) * 0.8):]\n",
    "\n",
    "        predictions = []\n",
    "        \n",
    "        # forecast over the period of the test split and fit the AutoReg function \n",
    "        for i in range(len(test)):\n",
    "            model = AutoReg(historic,data[1],period=duration,seasonal=seasonal_period)\n",
    "            model_fit = model.fit()\n",
    "            pred = model_fit.predict(start=len(historic), end=len(historic),dynamic=False)\n",
    "            predictions.append(pred[0])\n",
    "            historic.append(test[i])\n",
    "            \n",
    "        predictions = pd.Series(predictions, index=test.index, name=component)\n",
    "        prediction_results.append(predictions)\n",
    "    \n",
    "    if decomp=='multiplicative': \n",
    "        # Multiplying each decompoosed component forecast to recompose into a single forecast \n",
    "        recomposed_preds = pd.concat(prediction_results,axis=1).prod(axis=1)\n",
    "        recomposed_preds.name = 'recomposed_preds'\n",
    "        # removal of negative forecasts \n",
    "        recomposed_preds = recomposed_preds.where(recomposed_preds > 0,0)\n",
    "    else:\n",
    "         # Adding each decompoosed component forecast to recompose into a single forecast \n",
    "        recomposed_preds = pd.concat(prediction_results,axis=1).sum(axis=1)\n",
    "        recomposed_preds.name = 'recomposed_preds'\n",
    "         # removal of negative forecasts\n",
    "        recomposed_preds = recomposed_preds.where(recomposed_preds > 0,0)\n",
    "     \n",
    "    # root mean squared error \n",
    "    rmse = np.sqrt(mean_squared_error(data[2].iloc[int(len(data[2]) * 0.8):], recomposed_preds))\n",
    "    # mean absolutely scaled error \n",
    "    mase=MASE(pd.Series(historic),data[2].iloc[int(len(data[2]) * 0.8):],recomposed_preds)\n",
    "    \n",
    "    return (recomposed_preds,rmse,mase)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**POSSIBLE LIMITATIONS -**\n",
    "\n",
    "The function in itself **does not perform any data stationarity transformations or evaluations**. This essentially owes to the fact that there is a substantial variation in stationarity behaviors of the products in the given data, and attaining stationarity through transformations for each product might require a varied set of transformation operations. Hence, this step has been descoped from the functionality. \n",
    "\n",
    "**POSSIBLE BENEFITS -** \n",
    "\n",
    "The function automatically identifies the **appropriate decomposition methodology for a given product**. This is estimated by analysing autocorrelations between the residuals of each decomposition method and returning the ones with the least sum of squares. \n",
    "\n",
    "The **seasonal arguments** in the input allow the user to enforce control over the seasonal magnitude of the given product. For Eg: if a product X showcases yearly seasonality in store Y then the user could call the function as follows -\n",
    "\n",
    "**forecast_func(X,Y,True,360)**\n",
    "\n",
    "where the True parameter stands for the fact that the product showcases seasonality and 360 is the frequency of seasonality.\n",
    "As the data has daily samples, on a yearly scale, yearly seasonal frequency would be equivalent to 360 days. Please note that 360 should be enetered as an Integer without any unit. \n",
    "\n",
    "Also, the last argument is an optional parameter, if Seasonality is set to FALSE, the function would defualt pass the value \n",
    "for seasonal frequency as 0 days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REFERENCES** \n",
    "\n",
    "* https://www.statsmodels.org/stable/examples/notebooks/generated/autoregressions.html\n",
    "* https://www.statsmodels.org/stable/generated/statsmodels.tsa.ar_model.AutoReg.html\n",
    "* https://otexts.com/fpp2/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
